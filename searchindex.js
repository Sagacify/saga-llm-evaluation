Search.setIndex({"docnames": ["index", "modules", "sagacify_llm_evaluation", "sagacify_llm_evaluation.helpers", "sagacify_llm_evaluation.model", "sagacify_llm_evaluation.resources"], "filenames": ["index.rst", "modules.rst", "sagacify_llm_evaluation.rst", "sagacify_llm_evaluation.helpers.rst", "sagacify_llm_evaluation.model.rst", "sagacify_llm_evaluation.resources.rst"], "titles": ["Welcome to Sagacify LLM Evaluation Library\u2019s documentation!", "saga-llm-evaluation", "sagacify_llm_evaluation package", "sagacify_llm_evaluation.helpers package", "sagacify_llm_evaluation.model package", "sagacify_llm_evaluation.resources package"], "terms": {"i": [0, 2, 3], "versatil": 0, "python": 0, "design": 0, "perform": 0, "larg": 0, "languag": [0, 3], "model": [0, 1, 2, 3], "natur": 0, "process": 0, "nlp": [0, 3], "task": [0, 2, 3], "develop": 0, "index": 0, "modul": [0, 1], "search": [0, 3], "page": 0, "sagacify_llm_evalu": 1, "packag": 1, "subpackag": 1, "helper": [1, 2], "submodul": 1, "embedding_metr": [1, 2], "language_metr": [1, 2], "llm_metric": [1, 2], "util": [1, 2], "content": 1, "resourc": [1, 2], "score": [1, 3], "llmscorer": [1, 2], "add_geval_aspect": [1, 2], "add_geval_task": [1, 2], "add_gptscore_templ": [1, 2], "get_model": [1, 2], "bertscor": [2, 3], "comput": [2, 3], "mauv": [2, 3], "bleurtscor": [2, 3], "qsquar": [2, 3], "get_answ": [2, 3], "get_answer_candid": [2, 3], "get_questions_beam": [2, 3], "single_question_scor": [2, 3], "geval": [2, 3], "add_aspect": [2, 3], "add_task": [2, 3], "get_cot": [2, 3], "get_predict": [2, 3], "get_prompt": [2, 3], "get_scor": [2, 3], "gptscore": [2, 3], "add_templ": [2, 3], "selfcheckgpt": [2, 3], "metadataextractor": [2, 3], "add_custom_extractor": [2, 3], "add_regex_match_count": [2, 3], "add_word_regex_matches_count": [2, 3], "check_list_typ": [2, 3], "clean_text": [2, 3], "filter_class_input": [2, 3], "filter_quest": [2, 3], "get_llama_model": [2, 3], "load_json": [2, 3], "non_person": [2, 3], "raw_f1_scor": [2, 3], "class": [2, 3], "metric": [2, 3], "bert_scor": 2, "bleurt": [2, 3], "q_squar": 2, "none": [2, 3], "eval_model": [2, 3], "config": 2, "sourc": [2, 3], "base": [2, 3], "object": [2, 3], "code": [2, 3], "str": [2, 3], "name": [2, 3], "prompt": [2, 3], "thi": [2, 3], "function": [2, 3], "add": [2, 3], "an": [2, 3], "aspect": [2, 3], "pleas": [2, 3], "try": [2, 3], "follow": [2, 3], "exampl": [2, 3], "pattern": [2, 3], "ensur": [2, 3], "consist": [2, 3], "coh": [2, 3], "coher": [2, 3], "1": [2, 3], "5": [2, 3], "collect": [2, 3], "qualiti": [2, 3], "all": [2, 3], "sentenc": [2, 3], "we": [2, 3], "align": [2, 3], "dimens": [2, 3], "duc": [2, 3], "question": [2, 3], "structur": [2, 3], "wherebi": [2, 3], "summari": [2, 3], "should": [2, 3], "well": [2, 3], "organ": [2, 3], "The": [2, 3], "just": [2, 3], "heap": [2, 3], "relat": [2, 3], "inform": [2, 3], "build": [2, 3], "from": [2, 3], "bodi": [2, 3], "about": [2, 3], "topic": [2, 3], "paramet": [2, 3], "definit": [2, 3], "summ": [2, 3], "you": [2, 3], "given": [2, 3], "one": [2, 3], "written": [2, 3], "new": [2, 3], "articl": [2, 3], "your": [2, 3], "rate": [2, 3], "make": [2, 3], "sure": [2, 3], "read": [2, 3], "understand": [2, 3], "instruct": [2, 3], "carefulli": [2, 3], "keep": [2, 3], "document": [2, 3], "open": [2, 3], "while": [2, 3], "review": [2, 3], "refer": [2, 3], "need": [2, 3], "templat": [2, 3], "diag": [2, 3], "answer": [2, 3], "convers": [2, 3], "between": [2, 3], "human": [2, 3], "ai": [2, 3], "maintain": [2, 3], "good": [2, 3], "flow": [2, 3], "throughout": [2, 3], "ye": [2, 3], "b": [2, 3], "No": [2, 3], "user": [2, 3], "src": [2, 3], "pred": [2, 3], "user_prompt": [2, 3], "list": [2, 3], "predict": [2, 3], "knowledg": [2, 3], "dict": [2, 3], "option": [2, 3], "text": [2, 3], "us": [2, 3], "gener": [2, 3], "default": [2, 3], "file": [2, 3], "kei": [2, 3], "lang": 3, "en": 3, "model_typ": 3, "similar": 3, "each": 3, "token": 3, "candid": 3, "final": 3, "averag": 3, "If": 3, "anoth": 3, "multilingu": 3, "depend": 3, "see": 3, "abov": 3, "kwarg": 3, "return": 3, "contain": 3, "precis": 3, "recal": 3, "f1": 3, "type": 3, "featurize_model_nam": 3, "gpt2": 3, "differ": 3, "distribut": 3, "bigger": 3, "better": 3, "featur": 3, "check": 3, "http": 3, "huggingfac": 3, "co": 3, "space": 3, "evalu": 3, "more": 3, "checkpoint": 3, "tini": 3, "learnt": 3, "bert": 3, "specifi": 3, "qa_model": 3, "ktrapeznikov": 3, "albert": 3, "xlarg": 3, "v2": 3, "squad": 3, "qg_model": 3, "mrm8488": 3, "t5": 3, "finetun": 3, "ap": 3, "q\u00b2": 3, "free": 3, "aim": 3, "factual": 3, "ground": 3, "dialogu": 3, "system": 3, "approach": 3, "automat": 3, "github": 3, "com": 3, "orhonovich": 3, "q": 3, "squar": 3, "lan": 3, "It": 3, "mai": 3, "also": 3, "fr": 3, "singl": 3, "bool": 3, "fals": 3, "remove_person": 3, "true": 3, "respons": 3, "llm": 3, "context": 3, "onli": 3, "remov": 3, "person": 3, "pronoun": 3, "dictionari": 3, "avg_f1": 3, "float": 3, "among": 3, "param": 3, "ask": 3, "rtype": 3, "look": 3, "aswer": 3, "could": 3, "max_length": 3, "int": 3, "128": 3, "beam_siz": 3, "num_return": 3, "get": 3, "n": 3, "best": 3, "beam": 3, "max": 3, "length": 3, "size": 3, "number": 3, "pair": 3, "take": 3, "wa": 3, "higher": 3, "ar": 3, "A": 3, "tupl": 3, "itself": 3, "model_name_or_path": 3, "theblok": 3, "llama": 3, "2": 3, "7b": 3, "chat": 3, "gguf": 3, "model_basenam": 3, "q2_k": 3, "implement": 3, "inspir": 3, "propos": 3, "arxiv": 3, "org": 3, "pdf": 3, "2303": 3, "16634": 3, "download": 3, "hub": 3, "path": 3, "basenam": 3, "custom_prompt": 3, "method": 3, "descript": 3, "criterion": 3, "custom": 3, "chain": 3, "thought": 3, "must": 3, "2302": 3, "04166": 3, "system_prompt": 3, "": 3, "per": 3, "eval_model_name_or_path": 3, "eval_model_basenam": 3, "self": 3, "gpt": 3, "08896": 3, "transform": 3, "pretrainedmodel": 3, "n_sampl": 3, "which": 3, "sampl": 3, "metadata": 3, "extractor": 3, "elemeta": 3, "librari": 3, "abstractmetafeatureextractor": 3, "regex_rul": 3, "regex": 3, "rule": 3, "For": 3, "match": 3, "ha": 3, "word": 3, "extract": 3, "arrai": 3, "list_typ": 3, "otherwis": 3, "clean": 3, "punctuat": 3, "some": 3, "stopword": 3, "arg": 3, "python_funct": 3, "drop": 3, "filter": 3, "input": 3, "argument": 3, "python_class": 3, "exp_an": 3, "pred_an": 3, "expect": 3, "same": 3, "valid": 3, "NO": 3, "repo_id": 3, "filenam": 3, "model_path": 3, "repo": 3, "id": 3, "local": 3, "load": 3, "json": 3, "spaci": 3, "doe": 3, "a_gold": 3, "a_pr": 3, "raw": 3, "two": 3}, "objects": {"": [[2, 0, 0, "-", "sagacify_llm_evaluation"]], "sagacify_llm_evaluation": [[3, 0, 0, "-", "helpers"], [5, 0, 0, "-", "resources"], [2, 0, 0, "-", "score"]], "sagacify_llm_evaluation.helpers": [[3, 0, 0, "-", "embedding_metrics"], [3, 0, 0, "-", "language_metrics"], [3, 0, 0, "-", "llm_metrics"], [3, 0, 0, "-", "utils"]], "sagacify_llm_evaluation.helpers.embedding_metrics": [[3, 1, 1, "", "BERTScore"], [3, 1, 1, "", "MAUVE"]], "sagacify_llm_evaluation.helpers.embedding_metrics.BERTScore": [[3, 2, 1, "", "compute"]], "sagacify_llm_evaluation.helpers.embedding_metrics.MAUVE": [[3, 2, 1, "", "compute"]], "sagacify_llm_evaluation.helpers.language_metrics": [[3, 1, 1, "", "BLEURTScore"], [3, 1, 1, "", "QSquared"]], "sagacify_llm_evaluation.helpers.language_metrics.BLEURTScore": [[3, 2, 1, "", "compute"]], "sagacify_llm_evaluation.helpers.language_metrics.QSquared": [[3, 2, 1, "", "compute"], [3, 2, 1, "", "get_answer"], [3, 2, 1, "", "get_answer_candidates"], [3, 2, 1, "", "get_questions_beam"], [3, 2, 1, "", "single_question_score"]], "sagacify_llm_evaluation.helpers.llm_metrics": [[3, 1, 1, "", "GEval"], [3, 1, 1, "", "GPTScore"], [3, 1, 1, "", "SelfCheckGPT"]], "sagacify_llm_evaluation.helpers.llm_metrics.GEval": [[3, 2, 1, "", "add_aspect"], [3, 2, 1, "", "add_task"], [3, 2, 1, "", "compute"], [3, 2, 1, "", "get_cot"], [3, 2, 1, "", "get_prediction"], [3, 2, 1, "", "get_prompt"], [3, 2, 1, "", "get_score"]], "sagacify_llm_evaluation.helpers.llm_metrics.GPTScore": [[3, 2, 1, "", "add_template"], [3, 2, 1, "", "compute"], [3, 2, 1, "", "get_prompt"], [3, 2, 1, "", "get_score"]], "sagacify_llm_evaluation.helpers.llm_metrics.SelfCheckGPT": [[3, 2, 1, "", "compute"], [3, 2, 1, "", "get_prompt"], [3, 2, 1, "", "get_prompts"]], "sagacify_llm_evaluation.helpers.utils": [[3, 1, 1, "", "MetadataExtractor"], [3, 3, 1, "", "check_list_type"], [3, 3, 1, "", "clean_text"], [3, 3, 1, "", "filter_class_input"], [3, 3, 1, "", "filter_questions"], [3, 3, 1, "", "get_llama_model"], [3, 3, 1, "", "load_json"], [3, 3, 1, "", "non_personal"], [3, 3, 1, "", "raw_f1_score"]], "sagacify_llm_evaluation.helpers.utils.MetadataExtractor": [[3, 2, 1, "", "add_custom_extractor"], [3, 2, 1, "", "add_regex_match_count"], [3, 2, 1, "", "add_word_regex_matches_count"], [3, 2, 1, "", "compute"]], "sagacify_llm_evaluation.score": [[2, 1, 1, "", "LLMScorer"], [2, 3, 1, "", "get_model"]], "sagacify_llm_evaluation.score.LLMScorer": [[2, 2, 1, "", "add_geval_aspect"], [2, 2, 1, "", "add_geval_task"], [2, 2, 1, "", "add_gptscore_template"], [2, 2, 1, "", "score"]]}, "objtypes": {"0": "py:module", "1": "py:class", "2": "py:method", "3": "py:function"}, "objnames": {"0": ["py", "module", "Python module"], "1": ["py", "class", "Python class"], "2": ["py", "method", "Python method"], "3": ["py", "function", "Python function"]}, "titleterms": {"welcom": 0, "sagacifi": 0, "llm": [0, 1], "evalu": [0, 1], "librari": 0, "": 0, "document": 0, "indic": 0, "tabl": 0, "saga": 1, "sagacify_llm_evalu": [2, 3, 4, 5], "packag": [2, 3, 4, 5], "subpackag": 2, "submodul": [2, 3], "score": 2, "modul": [2, 3, 4, 5], "content": [2, 3, 4, 5], "helper": 3, "embedding_metr": 3, "language_metr": 3, "llm_metric": 3, "util": 3, "model": 4, "resourc": 5}, "envversion": {"sphinx.domains.c": 3, "sphinx.domains.changeset": 1, "sphinx.domains.citation": 1, "sphinx.domains.cpp": 9, "sphinx.domains.index": 1, "sphinx.domains.javascript": 3, "sphinx.domains.math": 2, "sphinx.domains.python": 4, "sphinx.domains.rst": 2, "sphinx.domains.std": 2, "sphinx.ext.todo": 2, "sphinx.ext.viewcode": 1, "sphinx": 60}, "alltitles": {"Welcome to Sagacify LLM Evaluation Library\u2019s documentation!": [[0, "welcome-to-sagacify-llm-evaluation-library-s-documentation"]], "Indices and tables": [[0, "indices-and-tables"]], "saga-llm-evaluation": [[1, "saga-llm-evaluation"]], "sagacify_llm_evaluation package": [[2, "sagacify-llm-evaluation-package"]], "Subpackages": [[2, "subpackages"]], "Submodules": [[2, "submodules"], [3, "submodules"]], "sagacify_llm_evaluation.score module": [[2, "module-sagacify_llm_evaluation.score"]], "Module contents": [[2, "module-sagacify_llm_evaluation"], [3, "module-sagacify_llm_evaluation.helpers"], [4, "module-contents"], [5, "module-sagacify_llm_evaluation.resources"]], "sagacify_llm_evaluation.helpers package": [[3, "sagacify-llm-evaluation-helpers-package"]], "sagacify_llm_evaluation.helpers.embedding_metrics module": [[3, "module-sagacify_llm_evaluation.helpers.embedding_metrics"]], "sagacify_llm_evaluation.helpers.language_metrics module": [[3, "module-sagacify_llm_evaluation.helpers.language_metrics"]], "sagacify_llm_evaluation.helpers.llm_metrics module": [[3, "module-sagacify_llm_evaluation.helpers.llm_metrics"]], "sagacify_llm_evaluation.helpers.utils module": [[3, "module-sagacify_llm_evaluation.helpers.utils"]], "sagacify_llm_evaluation.model package": [[4, "sagacify-llm-evaluation-model-package"]], "sagacify_llm_evaluation.resources package": [[5, "sagacify-llm-evaluation-resources-package"]]}, "indexentries": {"llmscorer (class in sagacify_llm_evaluation.score)": [[2, "sagacify_llm_evaluation.score.LLMScorer"]], "add_geval_aspect() (sagacify_llm_evaluation.score.llmscorer method)": [[2, "sagacify_llm_evaluation.score.LLMScorer.add_geval_aspect"]], "add_geval_task() (sagacify_llm_evaluation.score.llmscorer method)": [[2, "sagacify_llm_evaluation.score.LLMScorer.add_geval_task"]], "add_gptscore_template() (sagacify_llm_evaluation.score.llmscorer method)": [[2, "sagacify_llm_evaluation.score.LLMScorer.add_gptscore_template"]], "get_model() (in module sagacify_llm_evaluation.score)": [[2, "sagacify_llm_evaluation.score.get_model"]], "module": [[2, "module-sagacify_llm_evaluation"], [2, "module-sagacify_llm_evaluation.score"], [3, "module-sagacify_llm_evaluation.helpers"], [3, "module-sagacify_llm_evaluation.helpers.embedding_metrics"], [3, "module-sagacify_llm_evaluation.helpers.language_metrics"], [3, "module-sagacify_llm_evaluation.helpers.llm_metrics"], [3, "module-sagacify_llm_evaluation.helpers.utils"], [5, "module-sagacify_llm_evaluation.resources"]], "sagacify_llm_evaluation": [[2, "module-sagacify_llm_evaluation"]], "sagacify_llm_evaluation.score": [[2, "module-sagacify_llm_evaluation.score"]], "score() (sagacify_llm_evaluation.score.llmscorer method)": [[2, "sagacify_llm_evaluation.score.LLMScorer.score"]], "bertscore (class in sagacify_llm_evaluation.helpers.embedding_metrics)": [[3, "sagacify_llm_evaluation.helpers.embedding_metrics.BERTScore"]], "bleurtscore (class in sagacify_llm_evaluation.helpers.language_metrics)": [[3, "sagacify_llm_evaluation.helpers.language_metrics.BLEURTScore"]], "geval (class in sagacify_llm_evaluation.helpers.llm_metrics)": [[3, "sagacify_llm_evaluation.helpers.llm_metrics.GEval"]], "gptscore (class in sagacify_llm_evaluation.helpers.llm_metrics)": [[3, "sagacify_llm_evaluation.helpers.llm_metrics.GPTScore"]], "mauve (class in sagacify_llm_evaluation.helpers.embedding_metrics)": [[3, "sagacify_llm_evaluation.helpers.embedding_metrics.MAUVE"]], "metadataextractor (class in sagacify_llm_evaluation.helpers.utils)": [[3, "sagacify_llm_evaluation.helpers.utils.MetadataExtractor"]], "qsquared (class in sagacify_llm_evaluation.helpers.language_metrics)": [[3, "sagacify_llm_evaluation.helpers.language_metrics.QSquared"]], "selfcheckgpt (class in sagacify_llm_evaluation.helpers.llm_metrics)": [[3, "sagacify_llm_evaluation.helpers.llm_metrics.SelfCheckGPT"]], "add_aspect() (sagacify_llm_evaluation.helpers.llm_metrics.geval method)": [[3, "sagacify_llm_evaluation.helpers.llm_metrics.GEval.add_aspect"]], "add_custom_extractor() (sagacify_llm_evaluation.helpers.utils.metadataextractor method)": [[3, "sagacify_llm_evaluation.helpers.utils.MetadataExtractor.add_custom_extractor"]], "add_regex_match_count() (sagacify_llm_evaluation.helpers.utils.metadataextractor method)": [[3, "sagacify_llm_evaluation.helpers.utils.MetadataExtractor.add_regex_match_count"]], "add_task() (sagacify_llm_evaluation.helpers.llm_metrics.geval method)": [[3, "sagacify_llm_evaluation.helpers.llm_metrics.GEval.add_task"]], "add_template() (sagacify_llm_evaluation.helpers.llm_metrics.gptscore method)": [[3, "sagacify_llm_evaluation.helpers.llm_metrics.GPTScore.add_template"]], "add_word_regex_matches_count() (sagacify_llm_evaluation.helpers.utils.metadataextractor method)": [[3, "sagacify_llm_evaluation.helpers.utils.MetadataExtractor.add_word_regex_matches_count"]], "check_list_type() (in module sagacify_llm_evaluation.helpers.utils)": [[3, "sagacify_llm_evaluation.helpers.utils.check_list_type"]], "clean_text() (in module sagacify_llm_evaluation.helpers.utils)": [[3, "sagacify_llm_evaluation.helpers.utils.clean_text"]], "compute() (sagacify_llm_evaluation.helpers.embedding_metrics.bertscore method)": [[3, "sagacify_llm_evaluation.helpers.embedding_metrics.BERTScore.compute"]], "compute() (sagacify_llm_evaluation.helpers.embedding_metrics.mauve method)": [[3, "sagacify_llm_evaluation.helpers.embedding_metrics.MAUVE.compute"]], "compute() (sagacify_llm_evaluation.helpers.language_metrics.bleurtscore method)": [[3, "sagacify_llm_evaluation.helpers.language_metrics.BLEURTScore.compute"]], "compute() (sagacify_llm_evaluation.helpers.language_metrics.qsquared method)": [[3, "sagacify_llm_evaluation.helpers.language_metrics.QSquared.compute"]], "compute() (sagacify_llm_evaluation.helpers.llm_metrics.geval method)": [[3, "sagacify_llm_evaluation.helpers.llm_metrics.GEval.compute"]], "compute() (sagacify_llm_evaluation.helpers.llm_metrics.gptscore method)": [[3, "sagacify_llm_evaluation.helpers.llm_metrics.GPTScore.compute"]], "compute() (sagacify_llm_evaluation.helpers.llm_metrics.selfcheckgpt method)": [[3, "sagacify_llm_evaluation.helpers.llm_metrics.SelfCheckGPT.compute"]], "compute() (sagacify_llm_evaluation.helpers.utils.metadataextractor method)": [[3, "sagacify_llm_evaluation.helpers.utils.MetadataExtractor.compute"]], "filter_class_input() (in module sagacify_llm_evaluation.helpers.utils)": [[3, "sagacify_llm_evaluation.helpers.utils.filter_class_input"]], "filter_questions() (in module sagacify_llm_evaluation.helpers.utils)": [[3, "sagacify_llm_evaluation.helpers.utils.filter_questions"]], "get_answer() (sagacify_llm_evaluation.helpers.language_metrics.qsquared method)": [[3, "sagacify_llm_evaluation.helpers.language_metrics.QSquared.get_answer"]], "get_answer_candidates() (sagacify_llm_evaluation.helpers.language_metrics.qsquared method)": [[3, "sagacify_llm_evaluation.helpers.language_metrics.QSquared.get_answer_candidates"]], "get_cot() (sagacify_llm_evaluation.helpers.llm_metrics.geval method)": [[3, "sagacify_llm_evaluation.helpers.llm_metrics.GEval.get_cot"]], "get_llama_model() (in module sagacify_llm_evaluation.helpers.utils)": [[3, "sagacify_llm_evaluation.helpers.utils.get_llama_model"]], "get_prediction() (sagacify_llm_evaluation.helpers.llm_metrics.geval method)": [[3, "sagacify_llm_evaluation.helpers.llm_metrics.GEval.get_prediction"]], "get_prompt() (sagacify_llm_evaluation.helpers.llm_metrics.geval method)": [[3, "sagacify_llm_evaluation.helpers.llm_metrics.GEval.get_prompt"]], "get_prompt() (sagacify_llm_evaluation.helpers.llm_metrics.gptscore method)": [[3, "sagacify_llm_evaluation.helpers.llm_metrics.GPTScore.get_prompt"]], "get_prompt() (sagacify_llm_evaluation.helpers.llm_metrics.selfcheckgpt method)": [[3, "sagacify_llm_evaluation.helpers.llm_metrics.SelfCheckGPT.get_prompt"]], "get_prompts() (sagacify_llm_evaluation.helpers.llm_metrics.selfcheckgpt method)": [[3, "sagacify_llm_evaluation.helpers.llm_metrics.SelfCheckGPT.get_prompts"]], "get_questions_beam() (sagacify_llm_evaluation.helpers.language_metrics.qsquared method)": [[3, "sagacify_llm_evaluation.helpers.language_metrics.QSquared.get_questions_beam"]], "get_score() (sagacify_llm_evaluation.helpers.llm_metrics.geval method)": [[3, "sagacify_llm_evaluation.helpers.llm_metrics.GEval.get_score"]], "get_score() (sagacify_llm_evaluation.helpers.llm_metrics.gptscore method)": [[3, "sagacify_llm_evaluation.helpers.llm_metrics.GPTScore.get_score"]], "load_json() (in module sagacify_llm_evaluation.helpers.utils)": [[3, "sagacify_llm_evaluation.helpers.utils.load_json"]], "non_personal() (in module sagacify_llm_evaluation.helpers.utils)": [[3, "sagacify_llm_evaluation.helpers.utils.non_personal"]], "raw_f1_score() (in module sagacify_llm_evaluation.helpers.utils)": [[3, "sagacify_llm_evaluation.helpers.utils.raw_f1_score"]], "sagacify_llm_evaluation.helpers": [[3, "module-sagacify_llm_evaluation.helpers"]], "sagacify_llm_evaluation.helpers.embedding_metrics": [[3, "module-sagacify_llm_evaluation.helpers.embedding_metrics"]], "sagacify_llm_evaluation.helpers.language_metrics": [[3, "module-sagacify_llm_evaluation.helpers.language_metrics"]], "sagacify_llm_evaluation.helpers.llm_metrics": [[3, "module-sagacify_llm_evaluation.helpers.llm_metrics"]], "sagacify_llm_evaluation.helpers.utils": [[3, "module-sagacify_llm_evaluation.helpers.utils"]], "single_question_score() (sagacify_llm_evaluation.helpers.language_metrics.qsquared method)": [[3, "sagacify_llm_evaluation.helpers.language_metrics.QSquared.single_question_score"]], "sagacify_llm_evaluation.resources": [[5, "module-sagacify_llm_evaluation.resources"]]}})